{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36bc6fb9",
   "metadata": {},
   "source": [
    "![Under Maintenance](https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExeHNuZWxoMHZheXZ6NXp0aGRlYnhucGcybXA2NWNlem5iZ3J2a2I1aSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/7ZoMAYSgQJ8oe5gCYE/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd0d31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# First, let's import all the libraries we need\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility (so we get the same results each time)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb0eda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n",
      "Batches per epoch: 938\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset (handwritten digits 0-9)\n",
    "# This is a classic dataset for learning deep learning\n",
    "\n",
    "# Transform: Convert images to tensors and normalize them\n",
    "# Normalization helps the model learn faster\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Mean and std of MNIST dataset\n",
    "])\n",
    "\n",
    "# Download and load training data\n",
    "train_dataset = datasets.MNIST(root='./datasets', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders (they feed data to the model in small batches)\n",
    "batch_size = 64  # Process 64 images at a time\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b9a3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
