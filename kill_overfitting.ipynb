{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36bc6fb9",
   "metadata": {},
   "source": [
    "![Under Maintenance](https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExeHNuZWxoMHZheXZ6NXp0aGRlYnhucGcybXA2NWNlem5iZ3J2a2I1aSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/7ZoMAYSgQJ8oe5gCYE/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f1da6",
   "metadata": {},
   "source": [
    "# Understanding and Solving Overfitting in Deep Learning\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "In this notebook, we'll explore:\n",
    "1. What overfitting is and why it happens\n",
    "2. How to intentionally create overfitting (to understand it better)\n",
    "3. How to fix it using **Dropout**\n",
    "4. How to fix it using **Batch Normalization**\n",
    "5. How to combine both techniques\n",
    "\n",
    "---\n",
    "\n",
    "## üìö What is Overfitting?\n",
    "\n",
    "**Simple Explanation:**\n",
    "Imagine you're studying for an exam by memorizing practice questions and their answers. You get 100% on practice tests, but when the real exam comes with slightly different questions, you fail!\n",
    "\n",
    "This is **overfitting**: Your model memorizes the training data perfectly but can't handle new, unseen data.\n",
    "\n",
    "**Signs of Overfitting:**\n",
    "- ‚úÖ Training accuracy: 99%\n",
    "- ‚ùå Test accuracy: 65%\n",
    "- The model is too focused on specific details in training data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd0d31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# First, let's import all the libraries we need\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility (so we get the same results each time)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cb0eda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n",
      "Batches per epoch: 938\n"
     ]
    }
   ],
   "source": [
    "# Load the MNIST dataset (handwritten digits 0-9)\n",
    "# This is a classic dataset for learning deep learning\n",
    "\n",
    "# Transform: Convert images to tensors and normalize them\n",
    "# Normalization helps the model learn faster\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Mean and std of MNIST dataset\n",
    "])\n",
    "\n",
    "# Download and load training data\n",
    "train_dataset = datasets.MNIST(root='./datasets', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders (they feed data to the model in small batches)\n",
    "batch_size = 64  # Process 64 images at a time\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b9a3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualize some examples from the dataset\n",
    "\n",
    "def show_samples(dataset, n_samples=10):\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(1, n_samples, i + 1)\n",
    "        image, label = dataset[i]\n",
    "        plt.imshow(image.squeeze(), cmap='gray')\n",
    "        plt.title(f\"Label: {label}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d161a3",
   "metadata": {},
   "source": [
    "### üí° What we see\n",
    "\n",
    "These are the actual images our model will learn from! Each is 28x28 pixels (very small). The goal is to teach the model to recognize which digit each image represents.\n",
    "\n",
    "---\n",
    "\n",
    "## üî¥ Model 1: Creating Overfitting (The Problem)\n",
    "\n",
    "Let's intentionally create a model that overfits. We'll make it **too complex** for the task, so it memorizes rather than learns patterns.\n",
    "\n",
    "**How we create overfitting:**\n",
    "1. Make the network very deep (many layers)\n",
    "2. Use many neurons (high capacity to memorize)\n",
    "3. Train for many epochs (give it time to memorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e979bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverfittingModel(nn.Module):\n",
    "    \"\"\"A model designed to overfit -- to many parameters!\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(OverfittingModel, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 512)\n",
    "        self.fc5 = nn.Linear(512, 10)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"This defines how data flows through the network.\"\"\"\n",
    "        x = x.view(-1, 784)  # Flatten the 28x28 image into a 784-dimensional vector\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.fc5(x)  # Output layer (no activation here, we'll use CrossEntropyLoss which applies softmax)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f63211",
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_model = OverfittingModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44f642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters in the overfitting model: 1195018\n",
      "Number of parameters in the input layer: 401408\n",
      "Model architecture:\n",
      "OverfittingModel(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc4): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc5): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in overfit_model.parameters())\n",
    "print(f\"Total number of parameters in the overfitting model: {total_params}\")\n",
    "print(f\"Number of parameters in the input layer: {overfit_model.fc1.weight.numel()}\")\n",
    "print(f\"Model architecture:\\n{overfit_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76fd4e2",
   "metadata": {},
   "source": [
    "### üí° Understanding the Model\n",
    "\n",
    "**What's happening:**\n",
    "- **nn.Linear(784, 512)**: A layer that connects 784 inputs to 512 neurons. Each connection has a weight (parameter) the model learns.\n",
    "- **ReLU**: \"Rectified Linear Unit\" - a simple function that helps the model learn complex patterns. Think of it as a decision: if input > 0, keep it; else, make it 0.\n",
    "- **Parameters**: Over 1 million! This is way too many for recognizing simple digits. It's like using a supercomputer to add 2+2.\n",
    "\n",
    "**Why this overfits:**\n",
    "With so many parameters, the model can memorize every single training image instead of learning general patterns.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4c2da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function - this is how the model learns\n",
    "\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Train the model for one epoch (one pass through all training data)\"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # Move data to GPU/CPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # 1. Zero the gradients (clear previous step's learning)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. Forward pass: make predictions\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # 3. Calculate loss (how wrong are the predictions?)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 4. Backward pass: calculate gradients (which direction to adjust weights)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Update weights using the optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Track statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94540a4",
   "metadata": {},
   "source": [
    "### üí° How Training Works\n",
    "\n",
    "**The Learning Loop:**\n",
    "1. **Forward Pass**: Show the model an image, it makes a prediction\n",
    "2. **Loss Calculation**: Compare prediction to the correct answer. How wrong was it?\n",
    "3. **Backward Pass**: Calculate how to adjust each weight to reduce the error\n",
    "4. **Weight Update**: Actually adjust the weights a tiny bit\n",
    "5. **Repeat**: Do this for all 60,000 images\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Optimizer**: The algorithm that decides how to update weights (we'll use Adam - a popular choice)\n",
    "- **Loss Function**: Measures how wrong the model is (CrossEntropyLoss for classification)\n",
    "- **Gradients**: The direction and amount to adjust each weight\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fd9de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function - check how well the model performs\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    \"\"\"Evaluate the model on test data\"\"\"\n",
    "    model.eval()  # Set model to evaluation mode (disables dropout, etc.)\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Don't calculate gradients (saves memory and time)\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_loss = running_loss / len(test_loader)\n",
    "    test_acc = 100 * correct / total\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97c50e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¥ Training Model 1: Overfitting Model\n",
      "==================================================\n",
      "Epoch [5/20]\n",
      "  Train Loss: 0.0554, Train Acc: 98.39%\n",
      "  Test Loss:  0.0772, Test Acc:  97.92%\n",
      "  Gap: 0.47%\n",
      "\n",
      "Epoch [10/20]\n",
      "  Train Loss: 0.0305, Train Acc: 99.16%\n",
      "  Test Loss:  0.0824, Test Acc:  98.20%\n",
      "  Gap: 0.96%\n",
      "\n",
      "Epoch [15/20]\n",
      "  Train Loss: 0.0248, Train Acc: 99.37%\n",
      "  Test Loss:  0.0906, Test Acc:  98.23%\n",
      "  Gap: 1.14%\n",
      "\n",
      "Epoch [20/20]\n",
      "  Train Loss: 0.0136, Train Acc: 99.66%\n",
      "  Test Loss:  0.1335, Test Acc:  97.91%\n",
      "  Gap: 1.75%\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train the overfitting model\n",
    "\n",
    "print(\"üî¥ Training Model 1: Overfitting Model\\n\" + \"=\"*50)\n",
    "\n",
    "# Setup training\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function for classification\n",
    "optimizer = optim.Adam(overfit_model.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n",
    "\n",
    "# Track history\n",
    "overfit_history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'test_loss': [], 'test_acc': []\n",
    "}\n",
    "\n",
    "n_epochs = 20  # Train for 20 complete passes through the data\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Train for one epoch\n",
    "    train_loss, train_acc = train_epoch(overfit_model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Evaluate on test data\n",
    "    test_loss, test_acc = evaluate(overfit_model, test_loader, criterion, device)\n",
    "    \n",
    "    # Save history\n",
    "    overfit_history['train_loss'].append(train_loss)\n",
    "    overfit_history['train_acc'].append(train_acc)\n",
    "    overfit_history['test_loss'].append(test_loss)\n",
    "    overfit_history['test_acc'].append(test_acc)\n",
    "    \n",
    "    # Print progress every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{n_epochs}]\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Test Loss:  {test_loss:.4f}, Test Acc:  {test_acc:.2f}%\")\n",
    "        print(f\"  Gap: {train_acc - test_acc:.2f}%\")  # The overfitting gap!\n",
    "        print()\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda7a00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
