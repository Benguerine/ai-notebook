{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b5c977",
   "metadata": {},
   "source": [
    "![Adversarail attacks cat gif](https://media2.giphy.com/media/v1.Y2lkPTc5MGI3NjExeGI4c3B5MmwyNzU4ZG40MXFlMzdpdHdyZG1iZnd4ZHNha2MzcGxtcyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3oKIPuM1xeVUMZqbq8/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1104ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7596d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9264490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:37<00:00, 266kB/s] \n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 181kB/s]\n",
      "  8%|▊         | 131k/1.65M [00:33<03:30, 7.20kB/s] "
     ]
    }
   ],
   "source": [
    "# Define transforms\n",
    "transform = T.ToTensor()\n",
    "\n",
    "# Load training and test datasets\n",
    "train_dataset = datasets.MNIST(root='./datasets', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8505e243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:06<00:00, 1.45MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 167kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:02<00:00, 817kB/s] \n",
      "100%|██████████| 4.54k/4.54k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, epochs=5, lr=0.001):\n",
    "    \"\"\"\n",
    "    Train the neural network on MNIST data\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            if batch_idx % 200 == 0:\n",
    "                print(f'Epoch {epoch+1}/{epochs}, Batch {batch_idx}/{len(train_loader)}, '\n",
    "                      f'Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%')\n",
    "        \n",
    "        print(f'Epoch {epoch+1} complete - Avg Loss: {total_loss/len(train_loader):.4f}, '\n",
    "              f'Train Acc: {100.*correct/total:.2f}%')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12309a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    \"\"\"\n",
    "    Test the model accuracy\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d5d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create and train the model\n",
    "model = SimpleNN()\n",
    "print(\"Training model...\")\n",
    "model = train_model(model, train_loader, epochs=5)\n",
    "\n",
    "# Test the trained model\n",
    "print(\"\\nTesting model...\")\n",
    "test_accuracy = test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b41e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, image, label, epsilon):\n",
    "    \"\"\"\n",
    "    Perform FGSM attack\n",
    "    \n",
    "    Args:\n",
    "        model: The neural network\n",
    "        image: Input image (requires gradient)\n",
    "        label: True label\n",
    "        epsilon: Perturbation magnitude\n",
    "    \n",
    "    Returns:\n",
    "        perturbed_image: Adversarial example\n",
    "    \"\"\"\n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "    loss = F.cross_entropy(output, label)\n",
    "    \n",
    "    # Backward pass to get gradients\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Get the sign of the gradient\n",
    "    data_grad = image.grad.data\n",
    "    \n",
    "    # Create adversarial example\n",
    "    perturbed_image = image + epsilon * data_grad.sign()\n",
    "    \n",
    "    # Clamp to valid image range [0, 1]\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    \n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a6520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a test image\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Select a sample from the test set\n",
    "image, label = test_dataset[0]\n",
    "image = image.unsqueeze(0).to(device)  # Add batch dimension\n",
    "label = torch.tensor([label]).to(device)\n",
    "\n",
    "# Enable gradient computation for the image\n",
    "image.requires_grad = True\n",
    "\n",
    "# Get original prediction\n",
    "original_output = model(image)\n",
    "original_pred = original_output.argmax(1).item()\n",
    "original_confidence = F.softmax(original_output, dim=1).max().item()\n",
    "\n",
    "print(f\"Original prediction: {original_pred} (confidence: {original_confidence:.4f})\")\n",
    "print(f\"True label: {label.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f3e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different epsilon values\n",
    "epsilons = [0.0, 0.05, 0.1, 0.15, 0.2, 0.3]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, epsilon in enumerate(epsilons):\n",
    "    # Reset gradient\n",
    "    if image.grad is not None:\n",
    "        image.grad.zero_()\n",
    "    \n",
    "    # Generate adversarial example\n",
    "    if epsilon == 0.0:\n",
    "        adv_image = image\n",
    "    else:\n",
    "        adv_image = fgsm_attack(model, image, label, epsilon)\n",
    "    \n",
    "    # Get prediction on adversarial example\n",
    "    with torch.no_grad():\n",
    "        adv_output = model(adv_image)\n",
    "        adv_pred = adv_output.argmax(1).item()\n",
    "        adv_confidence = F.softmax(adv_output, dim=1).max().item()\n",
    "    \n",
    "    # Visualize\n",
    "    axes[idx].imshow(adv_image.squeeze().cpu().detach().numpy(), cmap='gray')\n",
    "    axes[idx].set_title(f'ε={epsilon}\\nPred: {adv_pred} ({adv_confidence:.2f})', fontsize=10)\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # Mark if attack succeeded\n",
    "    if adv_pred != label.item():\n",
    "        axes[idx].set_title(f'ε={epsilon}\\nPred: {adv_pred} ({adv_confidence:.2f})\\n✓ ATTACK SUCCESS', \n",
    "                           fontsize=10, color='red')\n",
    "\n",
    "plt.suptitle(f'FGSM Attack - Original Label: {label.item()}', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate adversarial example with epsilon = 0.1\n",
    "epsilon = 0.1\n",
    "image.requires_grad = True\n",
    "if image.grad is not None:\n",
    "    image.grad.zero_()\n",
    "\n",
    "adv_image = fgsm_attack(model, image, label, epsilon)\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    original_output = model(image)\n",
    "    adv_output = model(adv_image)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(image.squeeze().cpu().detach().numpy(), cmap='gray')\n",
    "axes[0].set_title(f'Original\\nPrediction: {original_output.argmax(1).item()}\\nTrue Label: {label.item()}', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Adversarial image\n",
    "axes[1].imshow(adv_image.squeeze().cpu().detach().numpy(), cmap='gray')\n",
    "axes[1].set_title(f'Adversarial (ε={epsilon})\\nPrediction: {adv_output.argmax(1).item()}', fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Perturbation (amplified for visibility)\n",
    "perturbation = (adv_image - image).squeeze().cpu().detach().numpy()\n",
    "axes[2].imshow(perturbation * 10, cmap='seismic', vmin=-1, vmax=1)\n",
    "axes[2].set_title(f'Perturbation (×10)\\nMax: {perturbation.max():.4f}', fontsize=12)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOriginal prediction: {original_output.argmax(1).item()}\")\n",
    "print(f\"Adversarial prediction: {adv_output.argmax(1).item()}\")\n",
    "print(f\"Attack {'succeeded' if original_output.argmax(1).item() != adv_output.argmax(1).item() else 'failed'}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5268bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_attack(model, test_loader, epsilon, max_samples=1000):\n",
    "    \"\"\"\n",
    "    Evaluate attack success rate\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    \n",
    "    correct_original = 0\n",
    "    correct_adversarial = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        if total >= max_samples:\n",
    "            break\n",
    "            \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        images.requires_grad = True\n",
    "        \n",
    "        # Original predictions\n",
    "        outputs = model(images)\n",
    "        _, pred = outputs.max(1)\n",
    "        correct_original += pred.eq(labels).sum().item()\n",
    "        \n",
    "        # Generate adversarial examples\n",
    "        if epsilon > 0:\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            data_grad = images.grad.data\n",
    "            perturbed_images = images + epsilon * data_grad.sign()\n",
    "            perturbed_images = torch.clamp(perturbed_images, 0, 1)\n",
    "        else:\n",
    "            perturbed_images = images\n",
    "        \n",
    "        # Adversarial predictions\n",
    "        with torch.no_grad():\n",
    "            adv_outputs = model(perturbed_images)\n",
    "            _, adv_pred = adv_outputs.max(1)\n",
    "            correct_adversarial += adv_pred.eq(labels).sum().item()\n",
    "        \n",
    "        total += labels.size(0)\n",
    "    \n",
    "    original_acc = 100. * correct_original / total\n",
    "    adversarial_acc = 100. * correct_adversarial / total\n",
    "    \n",
    "    return original_acc, adversarial_acc\n",
    "\n",
    "# Test different epsilon values\n",
    "epsilons_test = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "accuracies = []\n",
    "\n",
    "print(\"Evaluating attack success rates...\\n\")\n",
    "for eps in epsilons_test:\n",
    "    orig_acc, adv_acc = evaluate_attack(model, test_loader, eps, max_samples=1000)\n",
    "    accuracies.append((orig_acc, adv_acc))\n",
    "    print(f\"ε = {eps:.2f}: Original Acc = {orig_acc:.2f}%, Adversarial Acc = {adv_acc:.2f}%\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "orig_accs = [acc[0] for acc in accuracies]\n",
    "adv_accs = [acc[1] for acc in accuracies]\n",
    "\n",
    "plt.plot(epsilons_test, orig_accs, 'b-o', label='Original Accuracy', linewidth=2)\n",
    "plt.plot(epsilons_test, adv_accs, 'r-o', label='Adversarial Accuracy', linewidth=2)\n",
    "plt.xlabel('Epsilon', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.title('FGSM Attack: Model Accuracy vs Epsilon', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c41ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
